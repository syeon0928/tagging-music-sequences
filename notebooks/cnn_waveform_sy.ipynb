{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa5c8c4cd82421f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:30:59.576769Z",
     "start_time": "2023-11-19T13:30:59.319694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/seuh/Tagging-Music-Sequences\n",
      "/home/seuh/Tagging-Music-Sequences/data/\n"
     ]
    }
   ],
   "source": [
    "# Set path variables\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "cwd = os.getcwd()\n",
    "project_dir = os.path.abspath(os.path.join(cwd, os.pardir))\n",
    "sys.path.append(project_dir)\n",
    "data_path = os.path.join(project_dir, 'data/')\n",
    "print(project_dir)\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92539e7afd45cfda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:31:03.726506Z",
     "start_time": "2023-11-19T13:30:59.327913Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.audio_dataset import *\n",
    "from torch.utils.data import DataLoader\n",
    "from src.trainer import Trainer\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e2cf8fd18c8c61a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:31:03.765356Z",
     "start_time": "2023-11-19T13:31:03.756726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "402651522b5fbecd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:31:03.782414Z",
     "start_time": "2023-11-19T13:31:03.764541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA Device Name: Quadro RTX 8000\n"
     ]
    }
   ],
   "source": [
    "# Make sure CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.cuda.get_device_name(torch.cuda.current_device())\n",
    "    print(f\"Current CUDA Device Name: {device_name}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Please check your system's configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2acb435a82d11b",
   "metadata": {},
   "source": [
    "# Waveform + CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38891c1d977f660d",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a5ac67d3dded785",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:31:03.782547Z",
     "start_time": "2023-11-19T13:31:03.771307Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load label annotation csv\n",
    "train_annotations = 'mtat_train_label.csv'\n",
    "val_annotations = 'mtat_val_label.csv'\n",
    "test_annotations = 'mtat_test_label.csv'\n",
    "\n",
    "# data path\n",
    "cwd = Path.cwd()\n",
    "DATA_DIR = cwd.parent / 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be497231d208e7b3",
   "metadata": {},
   "source": [
    "### FOR RAW AUDIO DATA\n",
    "\n",
    "Set transformation parameter to None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39d95e461181ad29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:31:04.106222Z",
     "start_time": "2023-11-19T13:31:03.779309Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define global parameters across all classes\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION_IN_SEC = 29.1\n",
    "\n",
    "train_data = AudioDS(annotations_file=train_annotations, \n",
    "                     data_dir=DATA_DIR, \n",
    "                     target_sample_rate=SAMPLE_RATE, \n",
    "                     target_length=DURATION_IN_SEC, \n",
    "                     transformation=None)\n",
    "\n",
    "val_data = AudioDS(annotations_file=val_annotations,\n",
    "                     data_dir=DATA_DIR,\n",
    "                     target_sample_rate=SAMPLE_RATE,\n",
    "                     target_length=DURATION_IN_SEC,\n",
    "                     transformation=None)\n",
    "\n",
    "test_data = AudioDS(annotations_file=val_annotations,\n",
    "                     data_dir=DATA_DIR,\n",
    "                     target_sample_rate=SAMPLE_RATE,\n",
    "                     target_length=DURATION_IN_SEC,\n",
    "                     transformation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3a103f8e90c3094",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:31:04.130623Z",
     "start_time": "2023-11-19T13:31:04.107886Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data from created datasets\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f01af1b54dad5fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:31:04.131431Z",
     "start_time": "2023-11-19T13:31:04.111584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406\n",
      "136\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))\n",
    "print(len(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93a965413b7f1aee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:31:04.844198Z",
     "start_time": "2023-11-19T13:31:04.117014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 1, 465600])\n",
      "Labels batch shape: torch.Size([32, 50])\n"
     ]
    }
   ],
   "source": [
    "# Display batch information\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88b4ab5aac317eef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:31:04.857470Z",
     "start_time": "2023-11-19T13:31:04.844869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file path: /home/seuh/Tagging-Music-Sequences/data/mtat/0/paul_berget-the_siena_manuscript_on_steel_string_guitar-06-recercar_6_steel_string_guitar-30-59.mp3\n",
      "Label: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)\n",
      "Decoded labels: ['classical', 'harpsichord']\n"
     ]
    }
   ],
   "source": [
    "# Retrieve a sample\n",
    "idx = 0\n",
    "waveform = train_features[idx]\n",
    "label = train_labels[idx]\n",
    "decoded_labels = train_data.decode_labels(label)\n",
    "file_path = train_data.get_filepath(idx)\n",
    "\n",
    "print(f\"Audio file path: {file_path}\")\n",
    "print(f\"Label: {label}\")\n",
    "print(f\"Decoded labels: {decoded_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9ebc2dce8648e4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:31:04.862814Z",
     "start_time": "2023-11-19T13:31:04.855004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 465600])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of waveform\n",
    "# first element: number of channels in our case 1\n",
    "# second element: number of samples in 30 seconds audio at a sampling rate of 16000 samples/s \n",
    "# -> 480000 = 30s * 16000 samples/s\n",
    "waveform.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4156651706ee987",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de16859034fdd5c3",
   "metadata": {},
   "source": [
    "### Front-end CNN+waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1d226ace81cb27d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:31:04.934066Z",
     "start_time": "2023-11-19T13:31:04.864497Z"
    }
   },
   "outputs": [],
   "source": [
    "class WaveformNet(nn.Module):\n",
    "    def __init__(self, num_classes=50):\n",
    "        super(WaveformNet, self).__init__()\n",
    "        \n",
    "        # Strided convolution to reduce dimensionality\n",
    "        self.strided_conv = nn.Conv1d(1, 128, kernel_size=3, stride=3)\n",
    "        self.bn0 = nn.BatchNorm1d(128)\n",
    "\n",
    "        # Convolutional blocks\n",
    "        self.conv_blocks = nn.ModuleList()\n",
    "        in_channels = 128\n",
    "        out_channels = 128\n",
    "        for i in range(8):\n",
    "            \n",
    "            if i == 3:  # 4th layer\n",
    "                out_channels = 256\n",
    "            if i == 7:  # Last layer\n",
    "                out_channels = 512\n",
    "                \n",
    "            self.conv_blocks.append(nn.Conv1d(in_channels, out_channels, kernel_size=3))\n",
    "            self.conv_blocks.append(nn.BatchNorm1d(out_channels))\n",
    "            self.conv_blocks.append(nn.ReLU())\n",
    "            self.conv_blocks.append(nn.MaxPool1d(kernel_size=3, stride=3))\n",
    "            in_channels = out_channels  \n",
    "\n",
    "        # Global max pooling\n",
    "        self.global_max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        # Adjust the input size of the first FC layer based on the output of the last convolutional block\n",
    "        self.fc1 = nn.Linear(512, 256)  # Adjust 128 based on the output channels of the last conv block\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial strided convolution\n",
    "        x = F.relu(self.bn0(self.strided_conv(x)))\n",
    "\n",
    "        # Convolutional blocks\n",
    "        for block in self.conv_blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        # Global max pooling\n",
    "        x = self.global_max_pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "505bc3bae902d6e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:31:10.854334Z",
     "start_time": "2023-11-19T13:31:07.897467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1          [-1, 128, 155200]             512\n",
      "       BatchNorm1d-2          [-1, 128, 155200]             256\n",
      "            Conv1d-3          [-1, 128, 155198]          49,280\n",
      "       BatchNorm1d-4          [-1, 128, 155198]             256\n",
      "              ReLU-5          [-1, 128, 155198]               0\n",
      "         MaxPool1d-6           [-1, 128, 51732]               0\n",
      "            Conv1d-7           [-1, 128, 51730]          49,280\n",
      "       BatchNorm1d-8           [-1, 128, 51730]             256\n",
      "              ReLU-9           [-1, 128, 51730]               0\n",
      "        MaxPool1d-10           [-1, 128, 17243]               0\n",
      "           Conv1d-11           [-1, 128, 17241]          49,280\n",
      "      BatchNorm1d-12           [-1, 128, 17241]             256\n",
      "             ReLU-13           [-1, 128, 17241]               0\n",
      "        MaxPool1d-14            [-1, 128, 5747]               0\n",
      "           Conv1d-15            [-1, 256, 5745]          98,560\n",
      "      BatchNorm1d-16            [-1, 256, 5745]             512\n",
      "             ReLU-17            [-1, 256, 5745]               0\n",
      "        MaxPool1d-18            [-1, 256, 1915]               0\n",
      "           Conv1d-19            [-1, 256, 1913]         196,864\n",
      "      BatchNorm1d-20            [-1, 256, 1913]             512\n",
      "             ReLU-21            [-1, 256, 1913]               0\n",
      "        MaxPool1d-22             [-1, 256, 637]               0\n",
      "           Conv1d-23             [-1, 256, 635]         196,864\n",
      "      BatchNorm1d-24             [-1, 256, 635]             512\n",
      "             ReLU-25             [-1, 256, 635]               0\n",
      "        MaxPool1d-26             [-1, 256, 211]               0\n",
      "           Conv1d-27             [-1, 256, 209]         196,864\n",
      "      BatchNorm1d-28             [-1, 256, 209]             512\n",
      "             ReLU-29             [-1, 256, 209]               0\n",
      "        MaxPool1d-30              [-1, 256, 69]               0\n",
      "           Conv1d-31              [-1, 512, 67]         393,728\n",
      "      BatchNorm1d-32              [-1, 512, 67]           1,024\n",
      "             ReLU-33              [-1, 512, 67]               0\n",
      "        MaxPool1d-34              [-1, 512, 22]               0\n",
      "AdaptiveMaxPool1d-35               [-1, 512, 1]               0\n",
      "           Linear-36                  [-1, 256]         131,328\n",
      "           Linear-37                   [-1, 50]          12,850\n",
      "================================================================\n",
      "Total params: 1,379,506\n",
      "Trainable params: 1,379,506\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.78\n",
      "Forward/backward pass size (MB): 1089.07\n",
      "Params size (MB): 5.26\n",
      "Estimated Total Size (MB): 1096.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = WaveformNet(num_classes=50)\n",
    "input_size = (train_features.size()[1:])  \n",
    "summary(model.to(device), input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9798a2c09b877be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:31:32.981520Z",
     "start_time": "2023-11-19T13:31:31.962634Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate trainer\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 10\n",
    "num_classes = 50\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# train model\n",
    "trainer = Trainer(model, train_dataloader, val_dataloader, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bf7ff8e6e4c85e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:10:37.555563Z",
     "start_time": "2023-11-19T13:07:19.010163Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 1/10 [16:35<2:29:20, 995.62s/it, epoch=1, loss=0.000474]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] Validation Metrics: \n",
      ", Validation Accuracy: 0.05%, ROC AUC: 0.81, PR AUC: 0.24\n",
      "Epoch [1/10], Loss: 0.1926\n",
      "Epoch [1] Validation Metrics: \n",
      ", Validation Accuracy: 0.05%, ROC AUC: 0.81, PR AUC: 0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 2/10 [27:48<1:47:27, 805.98s/it, epoch=2, loss=0.000436]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2] Validation Metrics: \n",
      ", Validation Accuracy: 0.04%, ROC AUC: 0.83, PR AUC: 0.27\n",
      "Epoch [2/10], Loss: 0.1769\n",
      "Epoch [2] Validation Metrics: \n",
      ", Validation Accuracy: 0.04%, ROC AUC: 0.83, PR AUC: 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 3/10 [37:41<1:22:40, 708.67s/it, epoch=3, loss=0.000403]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3] Validation Metrics: \n",
      ", Validation Accuracy: 0.06%, ROC AUC: 0.85, PR AUC: 0.32\n",
      "Epoch [3/10], Loss: 0.1638\n",
      "Epoch [3] Validation Metrics: \n",
      ", Validation Accuracy: 0.06%, ROC AUC: 0.85, PR AUC: 0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 4/10 [47:27<1:06:01, 660.24s/it, epoch=4, loss=0.000387]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4] Validation Metrics: \n",
      ", Validation Accuracy: 0.06%, ROC AUC: 0.86, PR AUC: 0.33\n",
      "Epoch [4/10], Loss: 0.1569\n",
      "Epoch [4] Validation Metrics: \n",
      ", Validation Accuracy: 0.06%, ROC AUC: 0.86, PR AUC: 0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 5/10 [57:16<52:52, 634.55s/it, epoch=5, loss=0.000372]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5] Validation Metrics: \n",
      ", Validation Accuracy: 0.07%, ROC AUC: 0.87, PR AUC: 0.35\n",
      "Epoch [5/10], Loss: 0.1509\n",
      "Epoch [5] Validation Metrics: \n",
      ", Validation Accuracy: 0.07%, ROC AUC: 0.87, PR AUC: 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 6/10 [1:07:03<41:13, 618.35s/it, epoch=6, loss=0.000359]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6] Validation Metrics: \n",
      ", Validation Accuracy: 0.08%, ROC AUC: 0.87, PR AUC: 0.37\n",
      "Epoch [6/10], Loss: 0.1456\n",
      "Epoch [6] Validation Metrics: \n",
      ", Validation Accuracy: 0.08%, ROC AUC: 0.87, PR AUC: 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 7/10 [1:16:52<30:26, 608.81s/it, epoch=7, loss=0.000349]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7] Validation Metrics: \n",
      ", Validation Accuracy: 0.08%, ROC AUC: 0.88, PR AUC: 0.38\n",
      "Epoch [7/10], Loss: 0.1417\n",
      "Epoch [7] Validation Metrics: \n",
      ", Validation Accuracy: 0.08%, ROC AUC: 0.88, PR AUC: 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 8/10 [1:26:40<20:04, 602.14s/it, epoch=8, loss=0.00034] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8] Validation Metrics: \n",
      ", Validation Accuracy: 0.08%, ROC AUC: 0.88, PR AUC: 0.38\n",
      "Epoch [8/10], Loss: 0.1380\n",
      "Epoch [8] Validation Metrics: \n",
      ", Validation Accuracy: 0.08%, ROC AUC: 0.88, PR AUC: 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 9/10 [1:36:30<09:58, 598.40s/it, epoch=9, loss=0.000331]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9] Validation Metrics: \n",
      ", Validation Accuracy: 0.08%, ROC AUC: 0.88, PR AUC: 0.39\n",
      "Epoch [9/10], Loss: 0.1345\n",
      "Epoch [9] Validation Metrics: \n",
      ", Validation Accuracy: 0.08%, ROC AUC: 0.88, PR AUC: 0.39\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6e5b76e3bd762a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:31:44.147256Z",
     "start_time": "2023-11-19T13:31:43.962346Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model('../models/waveform_cnn.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aml-project)",
   "language": "python",
   "name": "aml-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
