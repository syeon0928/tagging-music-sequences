{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Set path variables\n",
    "import os\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "project_dir = os.path.abspath(os.path.join(cwd, os.pardir))\n",
    "sys.path.append(project_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T22:00:57.226816Z",
     "start_time": "2023-11-19T22:00:56.876744Z"
    }
   },
   "id": "20a9a70d4fab1c1b"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-19T22:01:03.436454Z",
     "start_time": "2023-11-19T22:00:56.887897Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from src import audio_util\n",
    "from src.audio_dataset import AudioDS"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modeling (Adjust to whatever model you want to do)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "262e806f361e2397"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data loading\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4398c382dda8d981"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### FOR RAW AUDIO DATA\n",
    "\n",
    "Set transformation parameter to None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21576f271a1d3d6a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# File names\n",
    "train_annotations = 'mtat_train_label.csv'\n",
    "val_annotations = 'mtat_val_label.csv'\n",
    "test_annotations = 'mtat_test_label.csv'\n",
    "\n",
    "# Data path\n",
    "from pathlib import Path\n",
    "cwd = Path.cwd()\n",
    "DATA_PATH = cwd.parent / 'data'\n",
    "\n",
    "# Define global parameters across all classes\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION_IN_SEC = 29.1\n",
    "\n",
    "train_data = AudioDS(annotations_file=train_annotations, \n",
    "                     data_dir=DATA_PATH, \n",
    "                     target_sample_rate=SAMPLE_RATE, \n",
    "                     target_length=DURATION_IN_SEC, \n",
    "                     transformation=None)\n",
    "\n",
    "val_data = AudioDS(annotations_file=val_annotations,\n",
    "                     data_dir=DATA_PATH,\n",
    "                     target_sample_rate=SAMPLE_RATE,\n",
    "                     target_length=DURATION_IN_SEC,\n",
    "                     transformation=None)\n",
    "\n",
    "test_data = AudioDS(annotations_file=val_annotations,\n",
    "                     data_dir=DATA_PATH,\n",
    "                     target_sample_rate=SAMPLE_RATE,\n",
    "                     target_length=DURATION_IN_SEC,\n",
    "                     transformation=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T22:01:03.892785Z",
     "start_time": "2023-11-19T22:01:03.438944Z"
    }
   },
   "id": "9539a0ecea0bf2af"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Load data from created datasets\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T22:01:03.893225Z",
     "start_time": "2023-11-19T22:01:03.828546Z"
    }
   },
   "id": "f5a368079a2380f0"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 465600])\n",
      "Labels batch shape: torch.Size([64, 50])\n"
     ]
    }
   ],
   "source": [
    "# Display batch information\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T22:01:06.066804Z",
     "start_time": "2023-11-19T22:01:03.840255Z"
    }
   },
   "id": "c3dbdf0dee5b8391"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file path: /Users/ab/Projects/Tagging-Music-Sequences/data/mtat/0/american_bach_soloists-joseph_haydn__masses-04-quoniam_tu_solus__allegro-30-59.mp3\n",
      "Label: tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)\n",
      "Decoded labels: ['classical', 'violin', 'cello']\n"
     ]
    }
   ],
   "source": [
    "# Retrieve a sample\n",
    "idx = 9\n",
    "waveform = train_features[idx]\n",
    "label = train_labels[idx]\n",
    "decoded_labels = train_data.decode_labels(label)\n",
    "file_path = train_data.get_filepath(idx)\n",
    "\n",
    "print(f\"Audio file path: {file_path}\")\n",
    "print(f\"Label: {label}\")\n",
    "print(f\"Decoded labels: {decoded_labels}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T22:01:06.090522Z",
     "start_time": "2023-11-19T22:01:06.065518Z"
    }
   },
   "id": "6a1023cfb21715c5"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 465600])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of waveform\n",
    "# first element: number of channels in our case 1\n",
    "# second element: number of samples in 30 seconds audio at a sampling rate of 16000 samples/s \n",
    "# -> 480000 = 30s * 16000 samples/s\n",
    "waveform.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T22:01:06.173075Z",
     "start_time": "2023-11-19T22:01:06.083558Z"
    }
   },
   "id": "543eb7198521fa72"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### FOR TRANSFORMED AUDIO DATA (mel spectrograms with db)\n",
    "\n",
    "Set transformation parameter to MEL_SPEC_DB_TRANSFORMATION"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99f3a652b52ce995"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Define global parameters across all classes\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION_IN_SEC = 29.1\n",
    "MEL_SPEC_DB_TRANSFORMATION = audio_util.get_audio_transforms(SAMPLE_RATE,\n",
    "                                                            n_fft=512,\n",
    "                                                            hop_length=256,\n",
    "                                                            n_mels=96,\n",
    "                                                            top_db=80)\n",
    "\n",
    "train_data_melspec = AudioDS(annotations_file=train_annotations, \n",
    "                     data_dir=DATA_PATH, \n",
    "                     target_sample_rate=SAMPLE_RATE, \n",
    "                     target_length=DURATION_IN_SEC, \n",
    "                     transformation=MEL_SPEC_DB_TRANSFORMATION)\n",
    "\n",
    "val_data_melspec = AudioDS(annotations_file=val_annotations,\n",
    "                     data_dir=DATA_PATH,\n",
    "                     target_sample_rate=SAMPLE_RATE,\n",
    "                     target_length=DURATION_IN_SEC,\n",
    "                     transformation=MEL_SPEC_DB_TRANSFORMATION)\n",
    "\n",
    "test_data_melspec = AudioDS(annotations_file=val_annotations,\n",
    "                     data_dir=DATA_PATH,\n",
    "                     target_sample_rate=SAMPLE_RATE,\n",
    "                     target_length=DURATION_IN_SEC,\n",
    "                     transformation=MEL_SPEC_DB_TRANSFORMATION)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T22:01:06.455296Z",
     "start_time": "2023-11-19T22:01:06.095565Z"
    }
   },
   "id": "b3912a17e0f2ee97"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Load data from created datasets\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataloader_melspec = DataLoader(train_data_melspec, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader_melspec = DataLoader(val_data_melspec, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader_melspec = DataLoader(test_data_melspec, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T22:01:06.463002Z",
     "start_time": "2023-11-19T22:01:06.458089Z"
    }
   },
   "id": "8c98eee38a365bf8"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 96, 1819])\n",
      "Labels batch shape: torch.Size([64, 50])\n"
     ]
    }
   ],
   "source": [
    "# Display batch information\n",
    "train_features, train_labels = next(iter(train_dataloader_melspec))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T22:01:08.804859Z",
     "start_time": "2023-11-19T22:01:06.466525Z"
    }
   },
   "id": "97a357b125b5b274"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file path: /Users/ab/Projects/Tagging-Music-Sequences/data/mtat/0/american_bach_soloists-joseph_haydn__masses-04-quoniam_tu_solus__allegro-30-59.mp3\n",
      "Label: tensor([1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)\n",
      "Decoded labels: ['guitar', 'classical', 'string', 'india']\n"
     ]
    }
   ],
   "source": [
    "# Retrieve a sample\n",
    "idx = 9\n",
    "mel_spec = train_features[idx]\n",
    "label = train_labels[idx]\n",
    "decoded_labels = train_data_melspec.decode_labels(label)\n",
    "file_path = train_data_melspec.get_filepath(idx)\n",
    "\n",
    "print(f\"Audio file path: {file_path}\")\n",
    "print(f\"Label: {label}\")\n",
    "print(f\"Decoded labels: {decoded_labels}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T22:01:08.811571Z",
     "start_time": "2023-11-19T22:01:08.800477Z"
    }
   },
   "id": "7bbb7bb56275f6bc"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 96, 1819])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [64, 1, 64, 3001]) tells you that your DataLoader is outputting batches \n",
    "# of 64 Mel spectrograms,\n",
    "# each with a single channel, \n",
    "# 64 Mel frequency bins, \n",
    "# and a sequence length of 3001 time frames\n",
    "mel_spec.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T22:01:08.867678Z",
     "start_time": "2023-11-19T22:01:08.810989Z"
    }
   },
   "id": "35fc820e0c94c359"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
