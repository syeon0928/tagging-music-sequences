{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T18:21:46.807323Z",
     "start_time": "2023-11-19T18:21:26.932274Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set path variables\n",
    "import os\n",
    "import sys\n",
    "cwd = os.getcwd()\n",
    "project_dir = os.path.abspath(os.path.join(cwd, os.pardir))\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from src.audio_dataset import AudioDS\n",
    "from src.audio_util import *\n",
    "from src.trainer import Trainer\n",
    "from src.model_alex import FullyConvNet4, FullyConvNet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd909e4f0f3729d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T18:21:52.919027Z",
     "start_time": "2023-11-19T18:21:52.915296Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device to GPU if possible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1d4b919e451b545",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T18:21:57.090309Z",
     "start_time": "2023-11-19T18:21:57.081392Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load label annotation csv\n",
    "train_annotations = 'mtat_train_label.csv'\n",
    "val_annotations = 'mtat_val_label.csv'\n",
    "test_annotations = 'mtat_test_label.csv'\n",
    "\n",
    "# Data path\n",
    "from pathlib import Path\n",
    "cwd = Path.cwd()\n",
    "DATA_DIR = cwd.parent / 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a51947bfa0d5ffe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T18:21:58.217190Z",
     "start_time": "2023-11-19T18:21:57.686960Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transformations on dataset\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION_IN_SEC = 29.1\n",
    "MEL_SPEC_DB_TRANSFORMATION = AudioUtil.get_audio_transforms(SAMPLE_RATE,\n",
    "                                                            n_fft=512,\n",
    "                                                            hop_length=256,\n",
    "                                                            n_mels=96,\n",
    "                                                            top_db=80)\n",
    "\n",
    "train_data = AudioDS(annotations_file=train_annotations,\n",
    "                     data_dir=DATA_DIR,\n",
    "                     target_sample_rate=SAMPLE_RATE,\n",
    "                     target_length=DURATION_IN_SEC,\n",
    "                     transformation=MEL_SPEC_DB_TRANSFORMATION)\n",
    "\n",
    "val_data = AudioDS(annotations_file=val_annotations,\n",
    "                   data_dir=DATA_DIR,\n",
    "                   target_sample_rate=SAMPLE_RATE,\n",
    "                   target_length=DURATION_IN_SEC,\n",
    "                   transformation=MEL_SPEC_DB_TRANSFORMATION)\n",
    "\n",
    "test_data = AudioDS(annotations_file=val_annotations,\n",
    "                    data_dir=DATA_DIR,\n",
    "                    target_sample_rate=SAMPLE_RATE,\n",
    "                    target_length=DURATION_IN_SEC,\n",
    "                    transformation=MEL_SPEC_DB_TRANSFORMATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "192e035be5eaab94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T18:22:02.467502Z",
     "start_time": "2023-11-19T18:22:02.458299Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad2d909def5cd005",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T18:22:05.853223Z",
     "start_time": "2023-11-19T18:22:05.840031Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ce2d4043561fffa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T18:22:09.195509Z",
     "start_time": "2023-11-19T18:22:07.634296Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 1, 96, 1819])\n",
      "Labels batch shape: torch.Size([32, 50])\n"
     ]
    }
   ],
   "source": [
    "# Display batch information\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d552d18239e8a2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### FCN4 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b489b3b45994717",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T18:22:29.537172Z",
     "start_time": "2023-11-19T18:22:11.857916Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "fcn4 = FullyConvNet4()\n",
    "\n",
    "# Instantiate trainer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(fcn4.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "trainer = Trainer(fcn4, train_dataloader, val_dataloader, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e56e47c41c569f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T18:23:58.487777Z",
     "start_time": "2023-11-19T18:23:36.185164Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 96, 1819]             160\n",
      "         MaxPool2d-2          [-1, 16, 48, 454]               0\n",
      "            Conv2d-3          [-1, 32, 48, 454]           4,640\n",
      "         MaxPool2d-4           [-1, 32, 12, 90]               0\n",
      "            Conv2d-5           [-1, 64, 12, 90]          18,496\n",
      "         MaxPool2d-6            [-1, 64, 4, 11]               0\n",
      "            Conv2d-7           [-1, 128, 4, 11]          73,856\n",
      "         MaxPool2d-8            [-1, 128, 1, 1]               0\n",
      "            Conv2d-9             [-1, 50, 1, 1]           6,450\n",
      "================================================================\n",
      "Total params: 103,602\n",
      "Trainable params: 103,602\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.67\n",
      "Forward/backward pass size (MB): 30.15\n",
      "Params size (MB): 0.40\n",
      "Estimated Total Size (MB): 31.22\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_size = (train_features.size()[1:])\n",
    "print(summary(fcn4, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51faac7a19a03e31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T19:33:21.025035Z",
     "start_time": "2023-11-19T18:24:06.480372Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [1:09:14<00:00, 415.44s/it, epoch=10, training loss=0.124, validation loss=0.142]\n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "trainer.train(epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afd442e8d26be418",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T19:34:48.367399Z",
     "start_time": "2023-11-19T19:33:21.014543Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1423581662494324,\n",
       " 0.08595194085027727,\n",
       " 0.8910117290756215,\n",
       " 0.4172853250163826)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10112a96aaac29d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T19:34:48.412911Z",
     "start_time": "2023-11-19T19:34:48.363722Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "path = '../models/spec_fcn4.pth'\n",
    "trainer.save_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "356c42f44bc7024a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T17:58:31.049965Z",
     "start_time": "2023-11-19T17:58:31.008467Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': [], 'train_accuracy': [], 'train_roc_auc': [], 'train_pr_auc': [], 'val_loss': [], 'val_accuracy': [], 'val_roc_auc': [], 'val_pr_auc': []}\n"
     ]
    }
   ],
   "source": [
    "# Load a model\n",
    "# path = '../models/test_alex.pth'\n",
    "# trainer.load_model(path)\n",
    "# print(trainer.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b55c010dfd94d3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### FCN5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24ff95fce1f9650f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T19:34:48.769579Z",
     "start_time": "2023-11-19T19:34:48.415030Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "fcn5 = FullyConvNet5()\n",
    "\n",
    "# Instantiate trainer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(fcn5.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "trainer_fcn5 = Trainer(fcn5, train_dataloader, val_dataloader, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d89af21ad4923808",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T19:34:48.774055Z",
     "start_time": "2023-11-19T19:34:48.767830Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1        [-1, 128, 96, 1819]           1,280\n",
      "         MaxPool2d-2         [-1, 128, 48, 454]               0\n",
      "            Conv2d-3         [-1, 256, 48, 454]         295,168\n",
      "         MaxPool2d-4         [-1, 256, 24, 113]               0\n",
      "            Conv2d-5         [-1, 512, 24, 113]       1,180,160\n",
      "         MaxPool2d-6          [-1, 512, 12, 28]               0\n",
      "            Conv2d-7         [-1, 1024, 12, 28]       4,719,616\n",
      "         MaxPool2d-8           [-1, 1024, 4, 5]               0\n",
      "            Conv2d-9           [-1, 2048, 4, 5]      18,876,416\n",
      "        MaxPool2d-10           [-1, 2048, 1, 1]               0\n",
      "           Conv2d-11             [-1, 50, 1, 1]         102,450\n",
      "================================================================\n",
      "Total params: 25,175,090\n",
      "Trainable params: 25,175,090\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.67\n",
      "Forward/backward pass size (MB): 254.69\n",
      "Params size (MB): 96.04\n",
      "Estimated Total Size (MB): 351.39\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "input_size = (train_features.size()[1:])\n",
    "print(summary(fcn5, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6899ad27a7c7facb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-19T19:34:48.773161Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 7/10 [54:26<23:18, 466.04s/it, epoch=7, training loss=0.12, validation loss=0.146]   "
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "trainer_fcn5.train(epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e8f52cbeef2a4d",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "trainer_fcn5.evaluate(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be776f1c78bfa15",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "path = '../models/spec_fcn5.pth'\n",
    "trainer.save_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e1573e0d9c2cf86",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': [], 'train_accuracy': [], 'train_roc_auc': [], 'train_pr_auc': [], 'val_loss': [], 'val_accuracy': [], 'val_roc_auc': [], 'val_pr_auc': []}\n"
     ]
    }
   ],
   "source": [
    "# Load a model\n",
    "# path = '../models/test_alex.pth'\n",
    "# trainer.load_model(path)\n",
    "# print(trainer.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aml-project)",
   "language": "python",
   "name": "aml-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
