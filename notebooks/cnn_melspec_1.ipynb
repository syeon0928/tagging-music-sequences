{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This is the first version of the CNN.\n",
    "It has a simple CNN that can serve as a baseline for more sophisticated models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5071153fc2225f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set path variables\n",
    "import os\n",
    "import sys\n",
    "\n",
    "cwd = os.getcwd()\n",
    "project_dir = os.path.abspath(os.path.join(cwd, os.pardir))\n",
    "sys.path.append(project_dir)\n",
    "data_path = os.path.join(project_dir, 'data/')\n",
    "print(project_dir)\n",
    "print(data_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20a9a70d4fab1c1b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for data loading process\n",
    "from src.data_loader import *\n",
    "import pandas as pd\n",
    "\n",
    "# load your libraries here\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modeling (Adjust to whatever model you want to do)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "262e806f361e2397"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data loading"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4398c382dda8d981"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load label annotation csv\n",
    "train_annotations = pd.read_csv(data_path + 'mtat_train_label.csv', index_col=0).reset_index(drop=True)\n",
    "val_annotations = pd.read_csv(data_path + 'mtat_val_label.csv', index_col=0).reset_index(drop=True)\n",
    "test_annotations = pd.read_csv(data_path + 'mtat_test_label.csv', index_col=0).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "872927e61b21ef60"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### FOR TRANSFORMED AUDIO DATA (mel spectrograms with db)\n",
    "\n",
    "Set transformation parameter to MEL_SPEC_DB_TRANSFORMATION"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "718882b2cb80c1fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define global parameters across all classes\n",
    "DATA_DIR = data_path\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION_IN_SEC = 30\n",
    "MEL_SPEC_DB_TRANSFORMATION = AudioUtil.get_audio_transforms(SAMPLE_RATE)\n",
    "\n",
    "train_data = AudioDS(annotations_file=train_annotations, \n",
    "                     data_dir=DATA_DIR, \n",
    "                     target_sample_rate=SAMPLE_RATE, \n",
    "                     target_length=DURATION_IN_SEC, \n",
    "                     transformation=MEL_SPEC_DB_TRANSFORMATION)\n",
    "\n",
    "val_data = AudioDS(annotations_file=val_annotations,\n",
    "                     data_dir=DATA_DIR,\n",
    "                     target_sample_rate=SAMPLE_RATE,\n",
    "                     target_length=DURATION_IN_SEC,\n",
    "                     transformation=MEL_SPEC_DB_TRANSFORMATION)\n",
    "\n",
    "test_data = AudioDS(annotations_file=val_annotations,\n",
    "                     data_dir=DATA_DIR,\n",
    "                     target_sample_rate=SAMPLE_RATE,\n",
    "                     target_length=DURATION_IN_SEC,\n",
    "                     transformation=MEL_SPEC_DB_TRANSFORMATION)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57439999b214c147"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load data from created datasets\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataloader_melspec = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader_melspec = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader_melspec = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d6da17335e28cf5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display batch information\n",
    "train_features, train_labels = next(iter(train_dataloader_melspec))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "128de8cd602b441e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Retrieve a sample\n",
    "idx = 9\n",
    "melspec = train_features[idx]\n",
    "label = train_labels[idx]\n",
    "decoded_labels = train_data.decode_labels(label)\n",
    "file_path = train_data.get_filepath(idx)\n",
    "\n",
    "print(f\"Audio file path: {file_path}\")\n",
    "print(f\"Label: {label}\")\n",
    "print(f\"Decoded labels: {decoded_labels}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b39cc5985fd1e85a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# shape of melspec\n",
    "# first dimension: number of channels (1 - mono, 2 - stereo)\n",
    "# second dimension: number of mel frequency bands\n",
    "# third dimension: number of time frames in spectogams\n",
    "melspec.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6d59b54b471bed4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline CNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc11abaae1fd9420"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CNN Class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "333537a36f556640"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available() else \n",
    "    \"mps\" if torch.backends.mps.is_available() else \n",
    "    \"cpu\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaf064e5c72b0da7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Max pooling\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 8 * 375, 500)  # Adjusted input dimensions\n",
    "        self.fc2 = nn.Linear(500, 50)  # 50 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        # Flatten the output for the fully connected layers\n",
    "        x = x.view(-1, 64 * 8 * 375)  # Adjusted flattening dimensions\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2469e6b451461d9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instantiation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fa37014cc64fbca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Move the model to the selected device\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98eea4fee3b16259"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and Validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5df2f6ab9c46a17a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training Loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab8eea6311b00072"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, device):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Training\")\n",
    "\n",
    "        for i, data in progress_bar:\n",
    "            # Get the input features and labels from the data loader\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Convert boolean labels to class indices if necessary\n",
    "            if labels.dtype == torch.bool:\n",
    "                labels = labels.type(torch.long)\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update running loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Update the progress bar\n",
    "            progress_bar.set_postfix({\"loss\": running_loss / (i + 1)})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac48c94d866d22eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validation Loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14dd39f4b9d0bd83"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def validate(dataloader, model, loss_fn, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Convert boolean labels to class indices if necessary\n",
    "            if y.dtype == torch.bool:\n",
    "                y = y.type(torch.long)\n",
    "                y = torch.argmax(y, dim=1)\n",
    "\n",
    "            pred = model(X)\n",
    "            val_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    val_loss /= len(dataloader.dataset)\n",
    "    correct /= len(dataloader.dataset)\n",
    "    print(f\"Validation Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {val_loss:>8f} \\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55803f41dbeb942c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run Training and Validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "413820ac527e841c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training with validation after every epoch\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    train(train_dataloader_melspec, model, criterion, optimizer, device) # Call Train loop\n",
    "    validate(val_dataloader_melspec, model, criterion, device) # Call validation loop\n",
    "    torch.save(model.state_dict(), f\"model_epoch_{epoch}.pth\") # Saves model state after every epoch\n",
    "\n",
    "print(\"Training and validation done!\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8231d6ced36eadf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5ffaf6697d53d3f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Convert boolean labels to class indices if necessary\n",
    "            if y.dtype == torch.bool:\n",
    "                y = y.type(torch.long)\n",
    "                y = torch.argmax(y, dim=1)\n",
    "\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= len(dataloader.dataset)\n",
    "    correct /= len(dataloader.dataset)\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a62650e5a9952cef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run Testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e26a06e8267dfbe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    test(test_dataloader_melspec, model, criterion, device)\n",
    "\n",
    "print(\"Testing done!\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4065d8134645aea0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
