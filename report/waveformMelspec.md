Ein wichtiger Teil unserer Arbeit ist es, den Maschinen die Musik verständlich zu machen. Unsere Modelle müssen in der Lage sein, Audiodateien in einer bestimmten form zu verstehen, damit es für sie möglich ist, mit diesen zu arbeiten. Zwei der am häufigsten verwendeten Methoden sind waveforms und spectograms.
Beide Formen sind Visualisierungen der Audiodatei. Die waveform ist die einfache rohe Form und zeigt die Amplitude über den Zeitverlauf. Spectograms entstehen durch Fourier Transformationen des Soundsignals und zeigen die Frequenz über den Zeitverlauf an, wobei die Einfärbung Infos zur Amplitude gibt. Melspectograms sind eine Version von spectograms bei der statt der Frequenz die die Mel Scale verwendet wird und anstatt der Amplitude eine Decibel Skala. Mel Spectograms haben zum Ziel, sound so darzustellen wie in Menschen hören. Daher unterscheidet sich die Mel Scale von der normalen frequenz skala, da Menschen Unterschiede zwischen verschiedenen Tonhähen unterschiedlich stark warnehmen und nur auf bestimmten Frequenz Bereichen überhaupt etwas hören \cite{doshi2021audio}.
Im Endergebnis haben wir somit auf verschiedene Weisen Audio Signale in images umgewandetl, und damit einen input geschaffen, der von Maschinen gut lesbar ist, z.B. durch CNNs.
